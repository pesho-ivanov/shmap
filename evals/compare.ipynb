{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "#from astropy import units as u\n",
    "import sys\n",
    "from readpaf import parse_paf\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sv\n",
    "\n",
    "#from itables import init_notebook_mode\n",
    "#init_notebook_mode(all_interactive=True)\n",
    "\n",
    "def to_latex(df, data, refname):\n",
    "    latex = \"\"\n",
    "    df.index = df.index.map(lambda x: f'\\\\{x}')\n",
    "    df.columns = df.columns.str.replace(' ', '\\\\\\\\')\n",
    "    df.columns = df.columns.str.replace('%', '\\%')\n",
    "    df.columns = df.columns.map(lambda x: '\\makecell{' + x + '}')\n",
    "    #df = df.astype(str).map(lambda x: x.rstrip('0').rstrip('.') if '.' in x else x)\n",
    "    latex += df.to_latex(escape=False, label=f'tab:{refname}', caption=data, float_format = lambda x: '{:0.2f}'.format(x) if pd.notna(x) else '-')\n",
    "    #latex += df.to_latex(float_format = lambda x: '{:0.2f}'.format(x) if pd.notna(x) else '-')\n",
    "    latex += '\\n'\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_length(df):\n",
    "    df_sorted = df.sort_values(by='target_start').reset_index(drop=True)\n",
    "    merged_intervals = []\n",
    "    current_start, current_end = df_sorted.iloc[0]['target_start'], df_sorted.iloc[0]['target_end']\n",
    "\n",
    "    for index, row in df_sorted.iterrows():\n",
    "        if index == 0:\n",
    "            continue\n",
    "        if row['target_start'] <= current_end:\n",
    "            current_end = max(current_end, row['target_end'])\n",
    "        else:\n",
    "            merged_intervals.append((current_start, current_end))\n",
    "            current_start, current_end = row['target_start'], row['target_end']\n",
    "\n",
    "    merged_intervals.append((current_start, current_end))\n",
    "    union_length = sum(end - start for start, end in merged_intervals)\n",
    "    return union_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc(a, b):\n",
    "    if b == 0:\n",
    "        return np.nan\n",
    "    return 100.0 * a / b\n",
    "\n",
    "def fasta2df(fn):\n",
    "    seqs = SeqIO.parse(fn, \"fasta\")\n",
    "    df = pd.DataFrame((str(s.id), str(s.seq)) for s in seqs)\n",
    "    df.columns = [\"ID\", \"Sequence\"]\n",
    "    return df\n",
    "\n",
    "def is_overlapping(a, sv_row):\n",
    "    return a.GT_from <= sv_row['END'] and sv_row['POS'] <= a.GT_to \n",
    "    \n",
    "min_overlap = 0.9\n",
    "\n",
    "# def is_correct(a):\n",
    "#     if a.GT_ref != a.target_name:\n",
    "#         return False\n",
    "#     if a.GT_strand != a.strand:\n",
    "#         return False\n",
    "#     union_from = min(a.GT_from, a.target_start)\n",
    "#     union_to = max(a.GT_to, a.target_end)\n",
    "\n",
    "#     intersect_from = max(a.GT_from, a.target_start)\n",
    "#     intersect_to = min(a.GT_to, a.target_end)\n",
    "#     overlaps = intersect_to - intersect_from >= min_overlap * (union_to - union_from)\n",
    "#     return overlaps\n",
    "\n",
    "def is_correct_labels(a, GT_l, target_l, debug=False):\n",
    "    if a.GT_ref != a.target_name:\n",
    "        return False\n",
    "    if a.GT_strand != a.strand:  # won't work for inversions\n",
    "        return False\n",
    "#    union_from = min(a.GT_from, a.target_start)\n",
    "#    union_to = max(a.GT_to, a.target_end)\n",
    "\n",
    "    GT_labels = Counter(target_l[a.GT_ref][a.GT_from:a.GT_to])\n",
    "    target_labels = Counter(GT_l[a.target_name][a.target_start:a.target_end])\n",
    "    #GT_labels = Counter(GT_l[a.GT_ref][a.GT_from:a.GT_to])\n",
    "    #target_labels = Counter(target_l[a.target_name][a.target_start:a.target_end])\n",
    "    intersection = GT_labels & target_labels\n",
    "    union = GT_labels | target_labels\n",
    "    overlaps = sum(intersection.values()) >= min_overlap * sum(union.values())\n",
    "\n",
    "    if debug:\n",
    "        display(a)\n",
    "        display('           GT from {} to {}'.format(a.GT_from, a.GT_to))\n",
    "        display('       target from {} to {}'.format(a.target_start, a.target_end))\n",
    "        display('    GT_labels from {} to {}'.format(min(GT_labels), max(GT_labels)))\n",
    "        display('target_labels from {} to {}'.format(min(target_labels), max(target_labels)))\n",
    "        display('{} >?= {} = {} * union {} => {}'.format(sum(intersection.values()), min_overlap * sum(union.values()), min_overlap, sum(union.values()), overlaps))\n",
    "    return overlaps\n",
    "\n",
    "def is_correct_labels_df(df: pd.DataFrame, GT_l, target_l, debug=False):\n",
    "    if (df.GT_ref != df.target_name).any():\n",
    "        return False\n",
    "    if (df.GT_strand != df.strand).any():  # won't work for inversions\n",
    "        return False\n",
    "\n",
    "    GT_ref, GT_from, GT_to = df.GT_ref.iloc[0], df.GT_from.iloc[0], df.GT_to.iloc[0]\n",
    "    assert (df.GT_ref == GT_ref).all() and (df.GT_from == GT_from).all() and (df.GT_to == GT_to).all()\n",
    "\n",
    "    GT_labels = Counter(target_l[GT_ref][GT_from:GT_to])\n",
    "    L = [ Counter(GT_l[a.target_name][a.target_start:a.target_end]) for a in df.itertuples() ]\n",
    "    target_labels = sum(L, Counter())\n",
    "    #GT_labels = Counter(GT_l[a.GT_ref][a.GT_from:a.GT_to])\n",
    "    #target_labels = Counter(target_l[a.target_name][a.target_start:a.target_end])\n",
    "    intersection = GT_labels & target_labels\n",
    "    union = GT_labels | target_labels\n",
    "    overlaps = sum(intersection.values()) >= min_overlap * sum(union.values())\n",
    "    return overlaps\n",
    "\n",
    "def read_falls_on_what_sv(a, vcf_df):\n",
    "    query_start = a['GT_from']\n",
    "    query_end = a['GT_to']\n",
    "    start_idx = vcf_df['POS'].searchsorted(query_start, side='right')\n",
    "    end_idx = vcf_df['END'].searchsorted(query_end, side='left')\n",
    "    overlap_df = vcf_df.iloc[start_idx:end_idx]\n",
    "    overlap_ch_df = overlap_df[overlap_df['CHROM'] == a['GT_ref']]\n",
    "    overlap_ch_sv = overlap_ch_df[(overlap_ch_df['POS'] <= query_end) & (overlap_ch_df['END'] >= query_start)]\n",
    "    #if len(overlap_ch_sv) > 0:\n",
    "    #    display(a, overlap_ch_sv)\n",
    "    if len(overlap_ch_sv) == 0:\n",
    "        return 'none'\n",
    "    elif len(overlap_ch_sv) == 1:\n",
    "        return overlap_ch_sv.iloc[0]['SVTYPE']\n",
    "    else:\n",
    "        return 'multi'\n",
    "\n",
    "def read_paf(pref, reads, experiment, tool, orig_l: dict, mutated_l: dict, vcf_df: pd.DataFrame):\n",
    "    #display(vcf_df)\n",
    "    paf_file = pref.with_suffix('.paf')\n",
    "    no_GT = False\n",
    "    if not paf_file.exists():\n",
    "        raise Exception(f\"File does not exist or is empty: {paf_file}\")\n",
    "    with open(paf_file) as handle:\n",
    "        df = parse_paf(handle, dataframe=True)\n",
    "        df['experiment'] = experiment\n",
    "        df['tool'] = tool\n",
    "        try:\n",
    "            df[ ['read_name', 'GT_ref', 'GT_from', 'GT_to', 'GT_strand'] ] = df['query_name'].str.split('!', expand=True)\n",
    "            df['GT_from'] = df['GT_from'].astype(int)\n",
    "            df['GT_to'] = df['GT_to'].astype(int)\n",
    "            #df['is_correct_labels'] = df.apply(lambda x: is_correct_labels(x, orig_l, mutated_l), axis=1)\n",
    "            #df['is_correct'] = df.apply(is_correct, axis=1)\n",
    "            df['is_correct'] = df.apply(lambda x: is_correct_labels(x, orig_l, mutated_l), axis=1)\n",
    "            df['start_diff'] = df.target_start - df.GT_from  # TODO: different coordinate systems!\n",
    "            df['end_diff'] = df.target_end - df.GT_to  # TODO: different coordinate systems!\n",
    "            df['read_sv'] = df.apply(lambda x: read_falls_on_what_sv(x, vcf_df), axis=1)\n",
    "        except ValueError as e:\n",
    "            display(e)\n",
    "            df['read_name'] = df['query_name']\n",
    "            #df['is_correct_labels'] = True\n",
    "            df['is_correct'] = True\n",
    "            df['start_diff'] = 0\n",
    "            df['end_diff'] = 0\n",
    "            df['read_sv'] = 'none'\n",
    "            no_GT = True\n",
    "        #display(df)\n",
    "    df = df.sort_values(['read_name', 'residue_matches'], ascending=[True, False], ignore_index=True)\n",
    "\n",
    "    # initialize from left to right\n",
    "    myNA = 'N/A'\n",
    "    #bad = 'bad'\n",
    "    unique = 'uniq'\n",
    "    multi = 'mult'\n",
    "    #bad_mappings_perc = bad+' mappings p.multiread'\n",
    "    paf = defaultdict(int)\n",
    "    #paf['unmapped'] = 0\n",
    "    #paf[unique] = 0\n",
    "    #paf[multi] = 0\n",
    "    #for suffix in ['', ' Q60']:\n",
    "    #    paf[bad + suffix] = 0\n",
    "    #    #if suffix == '':\n",
    "    #        #paf[multi+' '+bad+' group'] = 0\n",
    "    #        #paf[bad_mappings_perc] = 0\n",
    "    #    for unique_or_multi in [unique, multi]:\n",
    "    #        paf[bad + ' ' + unique_or_multi + suffix] = 0\n",
    "\n",
    "    def bad(sv_type):\n",
    "        return 'bad ' + sv_type\n",
    "\n",
    "    def process_group(group_first_index, group_last_index):\n",
    "        group = df.loc[group_first_index:group_last_index]\n",
    "        first_in_group = df.loc[group_first_index]\n",
    "        #group_is_correct = group['is_correct'].any()\n",
    "        group_is_correct = is_correct_labels_df(group, orig_l, mutated_l)\n",
    "        group_is_unique = len(group) == 1\n",
    "        suffix = 'Q60' if (group.mapping_quality == 60).all() else ''\n",
    "\n",
    "        unique_or_multi = unique if group_is_unique else multi\n",
    "        paf[unique_or_multi] += 1\n",
    "        if not group_is_correct:\n",
    "            paf[bad(suffix)] += 1\n",
    "            paf[unique_or_multi + ' ' +bad(suffix)] += 1\n",
    "            #if not group_is_unique:\n",
    "            #    paf[multi+' '+bad+' group'] += 1\n",
    "            #    paf[bad_mappings_perc] += 1\n",
    "            paf[bad(first_in_group['read_sv'])] += 1\n",
    "        paf[first_in_group['read_sv']] += 1\n",
    "\n",
    "    group_first_i, group_read_name = 0, df.loc[0, 'read_name']\n",
    "    for i, a in df.iterrows():\n",
    "        if a.read_name != group_read_name:\n",
    "            process_group(group_first_i, i-1)\n",
    "            group_first_i, group_read_name = i, a.read_name\n",
    "    process_group(group_first_i, len(df)-1)\n",
    "\n",
    "    paf['unmapped'] = reads - paf[unique] - paf[multi]\n",
    "\n",
    "    paf['aligned_with 0/1/2+_segments'] = '{} / {} / {} ({:.0f}%/{:.0f}%/{:.0f}%)'.format(\n",
    "        paf['unmapped'], paf[unique], paf[multi],\n",
    "        perc(paf['unmapped'], reads), perc(paf[unique], reads), perc(paf[multi], reads))\n",
    "    #for key in [unique, multi, 'unmapped', bad]:\n",
    "    #    paf[key] = '{} ({:.2f}%)'.format(paf[key], perc(paf[key], reads))\n",
    "\n",
    "    #if paf[multi] > 0:\n",
    "    #    paf[bad_mappings_perc] = '{:.2f}'.format(paf[bad_mappings_perc] / paf[multi])\n",
    "    #else:\n",
    "    #    paf[bad_mappings_perc] = myNA\n",
    "\n",
    "    paf['mean start diff'] = '{:.1f}'.format(df[df.is_correct].start_diff.mean())\n",
    "    paf['mean end diff'] = '{:.1f}'.format(df[df.is_correct].end_diff.mean())\n",
    " \n",
    "    #if no_GT:\n",
    "    #    for suff in ['', ' '+unique, ' '+multi]:\n",
    "    #        for suffsuff in ['', ' Q60']:\n",
    "    #            paf[bad + suff + suffsuff] = myNA \n",
    "    #        #paf[multi+' '+bad+' group'] = myNA\n",
    "    #        paf['addit '+bad+' aligns'] = myNA\n",
    "    #    paf['mean start diff'] = myNA\n",
    "    #    paf['mean end diff'] = myNA\n",
    "\n",
    "    paf['alignments depth'] = '{:.2f}'.format(sum(df['query_length']) / df.iloc[0]['target_length'])\n",
    "    union_len = union_length(df)\n",
    "    paf['covered reference'] = '{} ({:.2f}%)'.format(union_len, perc(union_len, df.iloc[0]['target_length']))\n",
    "\n",
    "    for sv_type in list(vcf_df['SVTYPE'].unique()) + ['none', 'multi']:\n",
    "        paf[bad(sv_type)] = '{} / {} ({:.2f}%)'.format(paf[bad(sv_type)], paf[sv_type], perc(paf[bad(sv_type)], paf[sv_type]))\n",
    "        paf.pop(sv_type)\n",
    "\n",
    "    # debug\n",
    "    #for row in df[df['read_sv'] != 'none'].itertuples():\n",
    "    #    is_correct_labels(row, orig_l, mutated_l, debug=True)\n",
    "\n",
    "    paf.pop('unmapped')\n",
    "    paf.pop(unique)\n",
    "    paf.pop(multi)\n",
    "\n",
    "    return pd.Series(paf, dtype='object')\n",
    "    \n",
    "def read_times(pref):\n",
    "    times = {}\n",
    "    with open(str(pref) + '.index.time') as f_index_time:\n",
    "        index_time, index_mem = map(float, f_index_time.readline().split())\n",
    "        times['index time'] = index_time #* u.second\n",
    "        #times['index_mem'] = index_mem / 2**20\n",
    "        with open(str(pref) + '.time') as f_time:\n",
    "            total_time, total_mem = map(float, f_time.readline().split())\n",
    "            #times['time total'] = total_time #* u.second\n",
    "            times['map time'] = total_time - times['index time']\n",
    "            times['memory'] = (total_mem / 2**20) #* u.GB\n",
    "    return pd.Series(times, dtype='object').map('{:.1f}'.format)\n",
    "\n",
    "def get_comparison_table(refname, readsim_refname, experiment, tools):\n",
    "    empty_cell = -1\n",
    "    alldf = pd.DataFrame()\n",
    "    alldf.name = experiment\n",
    "    ref = fasta2df(Path('refs') / (refname+'.fa'))\n",
    "    reads = fasta2df(Path('reads') / Path(experiment+'.fa'))\n",
    "\n",
    "    # SVs\n",
    "    orig_fa_dict = sv.read_fasta_file(Path('refs') / (refname+'.fa'))\n",
    "    orig_l = sv.gen_unique_labels(orig_fa_dict)\n",
    "    try:\n",
    "        vcf_df = sv.read_vcf(Path('refs') / (readsim_refname+'.vcf'))\n",
    "        assert((vcf_df.POS <= vcf_df.END).all())\n",
    "        vcf_df = vcf_df.sort_values(by='POS').reset_index(drop=True)\n",
    "        mutated_fa, mutated_l = sv.mutate(orig_fa_dict, orig_l, vcf_df)\n",
    "    except FileNotFoundError:\n",
    "        vcf_df = None\n",
    "        mutated_fa, mutated_l = orig_fa_dict, orig_l\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for tool in tqdm(tools, desc=f'Tools for {experiment}'):\n",
    "        d = Path(\"out\") / experiment / tool / tool\n",
    "        row = pd.Series({\n",
    "            'tool': tool,\n",
    "            'reads': len(reads),\n",
    "        })\n",
    "        row = pd.concat([row, read_paf(d, len(reads), experiment, tool, orig_l, mutated_l, vcf_df)])     # .paf\n",
    "        try:\n",
    "            row = pd.concat([row, read_times(d)])   # .time, .index.time\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while reading times {d}: {e}\")\n",
    "            row['index time'] = empty_cell\n",
    "            row['map time'] = empty_cell\n",
    "            row['memory'] = empty_cell\n",
    "        rows.append(row)\n",
    "    alldf = pd.DataFrame(rows)\n",
    "    alldf = alldf.set_index('tool')\n",
    "    alldf.index.name = None\n",
    "    return alldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a table to compare the mappers by accuracy, runtime (indexing and mapping) and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <style> table { font-family: \"Courier New\", Courier, monospace; } </style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tools for t2tChrY-readst2tChrY-SVs-a0.99-d0.1-l10000: 100%|██████████| 6/6 [01:00<00:00, 10.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_27158\">\n",
       "  <caption>t2tChrY-readst2tChrY-SVs-a0.99-d0.1-l10000</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_27158_level0_col0\" class=\"col_heading level0 col0\" >reads</th>\n",
       "      <th id=\"T_27158_level0_col1\" class=\"col_heading level0 col1\" >bad </th>\n",
       "      <th id=\"T_27158_level0_col2\" class=\"col_heading level0 col2\" >uniq bad </th>\n",
       "      <th id=\"T_27158_level0_col3\" class=\"col_heading level0 col3\" >bad none</th>\n",
       "      <th id=\"T_27158_level0_col4\" class=\"col_heading level0 col4\" >bad Q60</th>\n",
       "      <th id=\"T_27158_level0_col5\" class=\"col_heading level0 col5\" >uniq bad Q60</th>\n",
       "      <th id=\"T_27158_level0_col6\" class=\"col_heading level0 col6\" >bad INV</th>\n",
       "      <th id=\"T_27158_level0_col7\" class=\"col_heading level0 col7\" >bad DUP</th>\n",
       "      <th id=\"T_27158_level0_col8\" class=\"col_heading level0 col8\" >bad DEL</th>\n",
       "      <th id=\"T_27158_level0_col9\" class=\"col_heading level0 col9\" >bad INS</th>\n",
       "      <th id=\"T_27158_level0_col10\" class=\"col_heading level0 col10\" >bad multi</th>\n",
       "      <th id=\"T_27158_level0_col11\" class=\"col_heading level0 col11\" >aligned_with 0/1/2+_segments</th>\n",
       "      <th id=\"T_27158_level0_col12\" class=\"col_heading level0 col12\" >mean start diff</th>\n",
       "      <th id=\"T_27158_level0_col13\" class=\"col_heading level0 col13\" >mean end diff</th>\n",
       "      <th id=\"T_27158_level0_col14\" class=\"col_heading level0 col14\" >alignments depth</th>\n",
       "      <th id=\"T_27158_level0_col15\" class=\"col_heading level0 col15\" >covered reference</th>\n",
       "      <th id=\"T_27158_level0_col16\" class=\"col_heading level0 col16\" >index time</th>\n",
       "      <th id=\"T_27158_level0_col17\" class=\"col_heading level0 col17\" >map time</th>\n",
       "      <th id=\"T_27158_level0_col18\" class=\"col_heading level0 col18\" >memory</th>\n",
       "      <th id=\"T_27158_level0_col19\" class=\"col_heading level0 col19\" >mult bad </th>\n",
       "      <th id=\"T_27158_level0_col20\" class=\"col_heading level0 col20\" >mult bad Q60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_27158_level0_row0\" class=\"row_heading level0 row0\" >sweepmap</th>\n",
       "      <td id=\"T_27158_row0_col0\" class=\"data row0 col0\" >638</td>\n",
       "      <td id=\"T_27158_row0_col1\" class=\"data row0 col1\" >118</td>\n",
       "      <td id=\"T_27158_row0_col2\" class=\"data row0 col2\" >118</td>\n",
       "      <td id=\"T_27158_row0_col3\" class=\"data row0 col3\" >172 / 416 (41.35%)</td>\n",
       "      <td id=\"T_27158_row0_col4\" class=\"data row0 col4\" >144</td>\n",
       "      <td id=\"T_27158_row0_col5\" class=\"data row0 col5\" >144</td>\n",
       "      <td id=\"T_27158_row0_col6\" class=\"data row0 col6\" >24 / 58 (41.38%)</td>\n",
       "      <td id=\"T_27158_row0_col7\" class=\"data row0 col7\" >24 / 59 (40.68%)</td>\n",
       "      <td id=\"T_27158_row0_col8\" class=\"data row0 col8\" >14 / 25 (56.00%)</td>\n",
       "      <td id=\"T_27158_row0_col9\" class=\"data row0 col9\" >14 / 37 (37.84%)</td>\n",
       "      <td id=\"T_27158_row0_col10\" class=\"data row0 col10\" >14 / 43 (32.56%)</td>\n",
       "      <td id=\"T_27158_row0_col11\" class=\"data row0 col11\" >0 / 638 / 0 (0%/100%/0%)</td>\n",
       "      <td id=\"T_27158_row0_col12\" class=\"data row0 col12\" >-1082619.9</td>\n",
       "      <td id=\"T_27158_row0_col13\" class=\"data row0 col13\" >-1082562.3</td>\n",
       "      <td id=\"T_27158_row0_col14\" class=\"data row0 col14\" >0.10</td>\n",
       "      <td id=\"T_27158_row0_col15\" class=\"data row0 col15\" >5762584 (9.23%)</td>\n",
       "      <td id=\"T_27158_row0_col16\" class=\"data row0 col16\" >0.8</td>\n",
       "      <td id=\"T_27158_row0_col17\" class=\"data row0 col17\" >0.2</td>\n",
       "      <td id=\"T_27158_row0_col18\" class=\"data row0 col18\" >0.6</td>\n",
       "      <td id=\"T_27158_row0_col19\" class=\"data row0 col19\" >nan</td>\n",
       "      <td id=\"T_27158_row0_col20\" class=\"data row0 col20\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27158_level0_row1\" class=\"row_heading level0 row1\" >sweepmap-slow</th>\n",
       "      <td id=\"T_27158_row1_col0\" class=\"data row1 col0\" >638</td>\n",
       "      <td id=\"T_27158_row1_col1\" class=\"data row1 col1\" >118</td>\n",
       "      <td id=\"T_27158_row1_col2\" class=\"data row1 col2\" >118</td>\n",
       "      <td id=\"T_27158_row1_col3\" class=\"data row1 col3\" >93 / 416 (22.36%)</td>\n",
       "      <td id=\"T_27158_row1_col4\" class=\"data row1 col4\" >24</td>\n",
       "      <td id=\"T_27158_row1_col5\" class=\"data row1 col5\" >24</td>\n",
       "      <td id=\"T_27158_row1_col6\" class=\"data row1 col6\" >10 / 58 (17.24%)</td>\n",
       "      <td id=\"T_27158_row1_col7\" class=\"data row1 col7\" >14 / 59 (23.73%)</td>\n",
       "      <td id=\"T_27158_row1_col8\" class=\"data row1 col8\" >9 / 25 (36.00%)</td>\n",
       "      <td id=\"T_27158_row1_col9\" class=\"data row1 col9\" >9 / 37 (24.32%)</td>\n",
       "      <td id=\"T_27158_row1_col10\" class=\"data row1 col10\" >7 / 43 (16.28%)</td>\n",
       "      <td id=\"T_27158_row1_col11\" class=\"data row1 col11\" >0 / 638 / 0 (0%/100%/0%)</td>\n",
       "      <td id=\"T_27158_row1_col12\" class=\"data row1 col12\" >-1045488.8</td>\n",
       "      <td id=\"T_27158_row1_col13\" class=\"data row1 col13\" >-1045465.6</td>\n",
       "      <td id=\"T_27158_row1_col14\" class=\"data row1 col14\" >0.10</td>\n",
       "      <td id=\"T_27158_row1_col15\" class=\"data row1 col15\" >5981227 (9.58%)</td>\n",
       "      <td id=\"T_27158_row1_col16\" class=\"data row1 col16\" >1.0</td>\n",
       "      <td id=\"T_27158_row1_col17\" class=\"data row1 col17\" >60.7</td>\n",
       "      <td id=\"T_27158_row1_col18\" class=\"data row1 col18\" >0.7</td>\n",
       "      <td id=\"T_27158_row1_col19\" class=\"data row1 col19\" >nan</td>\n",
       "      <td id=\"T_27158_row1_col20\" class=\"data row1 col20\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27158_level0_row2\" class=\"row_heading level0 row2\" >mapquik</th>\n",
       "      <td id=\"T_27158_row2_col0\" class=\"data row2 col0\" >638</td>\n",
       "      <td id=\"T_27158_row2_col1\" class=\"data row2 col1\" >206</td>\n",
       "      <td id=\"T_27158_row2_col2\" class=\"data row2 col2\" >206</td>\n",
       "      <td id=\"T_27158_row2_col3\" class=\"data row2 col3\" >155 / 365 (42.47%)</td>\n",
       "      <td id=\"T_27158_row2_col4\" class=\"data row2 col4\" >31</td>\n",
       "      <td id=\"T_27158_row2_col5\" class=\"data row2 col5\" >31</td>\n",
       "      <td id=\"T_27158_row2_col6\" class=\"data row2 col6\" >17 / 52 (32.69%)</td>\n",
       "      <td id=\"T_27158_row2_col7\" class=\"data row2 col7\" >20 / 54 (37.04%)</td>\n",
       "      <td id=\"T_27158_row2_col8\" class=\"data row2 col8\" >10 / 21 (47.62%)</td>\n",
       "      <td id=\"T_27158_row2_col9\" class=\"data row2 col9\" >15 / 29 (51.72%)</td>\n",
       "      <td id=\"T_27158_row2_col10\" class=\"data row2 col10\" >20 / 41 (48.78%)</td>\n",
       "      <td id=\"T_27158_row2_col11\" class=\"data row2 col11\" >76 / 562 / 0 (12%/88%/0%)</td>\n",
       "      <td id=\"T_27158_row2_col12\" class=\"data row2 col12\" >-844564.3</td>\n",
       "      <td id=\"T_27158_row2_col13\" class=\"data row2 col13\" >-844567.0</td>\n",
       "      <td id=\"T_27158_row2_col14\" class=\"data row2 col14\" >0.09</td>\n",
       "      <td id=\"T_27158_row2_col15\" class=\"data row2 col15\" >5210632 (8.34%)</td>\n",
       "      <td id=\"T_27158_row2_col16\" class=\"data row2 col16\" >0.6</td>\n",
       "      <td id=\"T_27158_row2_col17\" class=\"data row2 col17\" >-0.0</td>\n",
       "      <td id=\"T_27158_row2_col18\" class=\"data row2 col18\" >1.5</td>\n",
       "      <td id=\"T_27158_row2_col19\" class=\"data row2 col19\" >nan</td>\n",
       "      <td id=\"T_27158_row2_col20\" class=\"data row2 col20\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27158_level0_row3\" class=\"row_heading level0 row3\" >blend</th>\n",
       "      <td id=\"T_27158_row3_col0\" class=\"data row3 col0\" >638</td>\n",
       "      <td id=\"T_27158_row3_col1\" class=\"data row3 col1\" >204</td>\n",
       "      <td id=\"T_27158_row3_col2\" class=\"data row3 col2\" >124</td>\n",
       "      <td id=\"T_27158_row3_col3\" class=\"data row3 col3\" >188 / 416 (45.19%)</td>\n",
       "      <td id=\"T_27158_row3_col4\" class=\"data row3 col4\" >66</td>\n",
       "      <td id=\"T_27158_row3_col5\" class=\"data row3 col5\" >61</td>\n",
       "      <td id=\"T_27158_row3_col6\" class=\"data row3 col6\" >22 / 58 (37.93%)</td>\n",
       "      <td id=\"T_27158_row3_col7\" class=\"data row3 col7\" >19 / 59 (32.20%)</td>\n",
       "      <td id=\"T_27158_row3_col8\" class=\"data row3 col8\" >12 / 25 (48.00%)</td>\n",
       "      <td id=\"T_27158_row3_col9\" class=\"data row3 col9\" >14 / 37 (37.84%)</td>\n",
       "      <td id=\"T_27158_row3_col10\" class=\"data row3 col10\" >15 / 43 (34.88%)</td>\n",
       "      <td id=\"T_27158_row3_col11\" class=\"data row3 col11\" >0 / 543 / 95 (0%/85%/15%)</td>\n",
       "      <td id=\"T_27158_row3_col12\" class=\"data row3 col12\" >-999652.6</td>\n",
       "      <td id=\"T_27158_row3_col13\" class=\"data row3 col13\" >-1000080.2</td>\n",
       "      <td id=\"T_27158_row3_col14\" class=\"data row3 col14\" >0.12</td>\n",
       "      <td id=\"T_27158_row3_col15\" class=\"data row3 col15\" >5610945 (8.98%)</td>\n",
       "      <td id=\"T_27158_row3_col16\" class=\"data row3 col16\" >1.1</td>\n",
       "      <td id=\"T_27158_row3_col17\" class=\"data row3 col17\" >3.9</td>\n",
       "      <td id=\"T_27158_row3_col18\" class=\"data row3 col18\" >0.2</td>\n",
       "      <td id=\"T_27158_row3_col19\" class=\"data row3 col19\" >80.000000</td>\n",
       "      <td id=\"T_27158_row3_col20\" class=\"data row3 col20\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27158_level0_row4\" class=\"row_heading level0 row4\" >minimap</th>\n",
       "      <td id=\"T_27158_row4_col0\" class=\"data row4 col0\" >638</td>\n",
       "      <td id=\"T_27158_row4_col1\" class=\"data row4 col1\" >110</td>\n",
       "      <td id=\"T_27158_row4_col2\" class=\"data row4 col2\" >53</td>\n",
       "      <td id=\"T_27158_row4_col3\" class=\"data row4 col3\" >91 / 416 (21.88%)</td>\n",
       "      <td id=\"T_27158_row4_col4\" class=\"data row4 col4\" >23</td>\n",
       "      <td id=\"T_27158_row4_col5\" class=\"data row4 col5\" >16</td>\n",
       "      <td id=\"T_27158_row4_col6\" class=\"data row4 col6\" >10 / 58 (17.24%)</td>\n",
       "      <td id=\"T_27158_row4_col7\" class=\"data row4 col7\" >8 / 59 (13.56%)</td>\n",
       "      <td id=\"T_27158_row4_col8\" class=\"data row4 col8\" >7 / 25 (28.00%)</td>\n",
       "      <td id=\"T_27158_row4_col9\" class=\"data row4 col9\" >8 / 37 (21.62%)</td>\n",
       "      <td id=\"T_27158_row4_col10\" class=\"data row4 col10\" >9 / 43 (20.93%)</td>\n",
       "      <td id=\"T_27158_row4_col11\" class=\"data row4 col11\" >0 / 557 / 81 (0%/87%/13%)</td>\n",
       "      <td id=\"T_27158_row4_col12\" class=\"data row4 col12\" >-1044700.3</td>\n",
       "      <td id=\"T_27158_row4_col13\" class=\"data row4 col13\" >-1044910.7</td>\n",
       "      <td id=\"T_27158_row4_col14\" class=\"data row4 col14\" >0.14</td>\n",
       "      <td id=\"T_27158_row4_col15\" class=\"data row4 col15\" >5763502 (9.23%)</td>\n",
       "      <td id=\"T_27158_row4_col16\" class=\"data row4 col16\" >1.6</td>\n",
       "      <td id=\"T_27158_row4_col17\" class=\"data row4 col17\" >17.8</td>\n",
       "      <td id=\"T_27158_row4_col18\" class=\"data row4 col18\" >0.4</td>\n",
       "      <td id=\"T_27158_row4_col19\" class=\"data row4 col19\" >57.000000</td>\n",
       "      <td id=\"T_27158_row4_col20\" class=\"data row4 col20\" >7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27158_level0_row5\" class=\"row_heading level0 row5\" >winnowmap</th>\n",
       "      <td id=\"T_27158_row5_col0\" class=\"data row5 col0\" >638</td>\n",
       "      <td id=\"T_27158_row5_col1\" class=\"data row5 col1\" >89</td>\n",
       "      <td id=\"T_27158_row5_col2\" class=\"data row5 col2\" >52</td>\n",
       "      <td id=\"T_27158_row5_col3\" class=\"data row5 col3\" >83 / 416 (19.95%)</td>\n",
       "      <td id=\"T_27158_row5_col4\" class=\"data row5 col4\" >41</td>\n",
       "      <td id=\"T_27158_row5_col5\" class=\"data row5 col5\" >25</td>\n",
       "      <td id=\"T_27158_row5_col6\" class=\"data row5 col6\" >9 / 58 (15.52%)</td>\n",
       "      <td id=\"T_27158_row5_col7\" class=\"data row5 col7\" >10 / 59 (16.95%)</td>\n",
       "      <td id=\"T_27158_row5_col8\" class=\"data row5 col8\" >9 / 25 (36.00%)</td>\n",
       "      <td id=\"T_27158_row5_col9\" class=\"data row5 col9\" >9 / 37 (24.32%)</td>\n",
       "      <td id=\"T_27158_row5_col10\" class=\"data row5 col10\" >10 / 43 (23.26%)</td>\n",
       "      <td id=\"T_27158_row5_col11\" class=\"data row5 col11\" >0 / 572 / 66 (0%/90%/10%)</td>\n",
       "      <td id=\"T_27158_row5_col12\" class=\"data row5 col12\" >-1064044.2</td>\n",
       "      <td id=\"T_27158_row5_col13\" class=\"data row5 col13\" >-1064158.5</td>\n",
       "      <td id=\"T_27158_row5_col14\" class=\"data row5 col14\" >0.12</td>\n",
       "      <td id=\"T_27158_row5_col15\" class=\"data row5 col15\" >5875957 (9.41%)</td>\n",
       "      <td id=\"T_27158_row5_col16\" class=\"data row5 col16\" >2.7</td>\n",
       "      <td id=\"T_27158_row5_col17\" class=\"data row5 col17\" >689.2</td>\n",
       "      <td id=\"T_27158_row5_col18\" class=\"data row5 col18\" >0.5</td>\n",
       "      <td id=\"T_27158_row5_col19\" class=\"data row5 col19\" >37.000000</td>\n",
       "      <td id=\"T_27158_row5_col20\" class=\"data row5 col20\" >16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a225e91c6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_374302/499495534.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdf_styled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvcf_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_caption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_styled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_latex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m#DF = pd.concat(dfs, keys=keys)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#display(DF)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "tools = ['sweepmap', 'sweepmap-slow', 'mapquik', 'blend', 'minimap', 'winnowmap'] \n",
    "#tools = ['sweepmap', 'minimap', 'winnowmap']\n",
    "experiments = [\n",
    "#    ('t2tChrY', 't2tChrY', 't2tChrY-readst2tChrY-a0.99-d10-l10000'),\n",
    "#    ('chm13',   'chm13',   'chm13-readschm13-a0.99-d0.1-l10000'),\n",
    "#    ('t2tChrY', 't2tChrY', 't2tChrY-readst2tChrY-a0.99-d1-l24000'),\n",
    "#    ('chm13',   'chm13',   'HG002_24kb'),\n",
    "\t('t2tChrY', 't2tChrY-SVs', 't2tChrY-readst2tChrY-SVs-a0.99-d0.1-l10000'),\n",
    "]\n",
    "\n",
    "pd.set_option('display.width', 100)\n",
    "css = \"\"\" <style> table { font-family: \"Courier New\", Courier, monospace; } </style> \"\"\"\n",
    "display(HTML(css))\n",
    "dfs = []\n",
    "keys = []\n",
    "for refname, readsim_refname, data in experiments:\n",
    "    vcf_df = get_comparison_table(refname=refname, readsim_refname=readsim_refname, experiment=data, tools=tools).round(2)\n",
    "    dfs.append(vcf_df)\n",
    "    keys.append(data)\n",
    "    df_styled = vcf_df.style.set_caption(data)\n",
    "    display(df_styled)\n",
    "    print(vcf_df.to_latex(escape=True))\n",
    "#DF = pd.concat(dfs, keys=keys)\n",
    "#display(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrlrrlllllllllllllrr}\n",
      "\\toprule\n",
      " & reads & bad  & uniq bad  & bad none & bad Q60 & uniq bad Q60 & bad INV & bad DUP & bad DEL & bad INS & bad multi & aligned_with 0/1/2+_segments & mean start diff & mean end diff & alignments depth & covered reference & index time & map time & memory & mult bad  & mult bad Q60 \\\\\n",
      "\\midrule\n",
      "sweepmap & 638 & 118 & 118 & 172 / 416 (41.35%) & 144 & 144 & 24 / 58 (41.38%) & 24 / 59 (40.68%) & 14 / 25 (56.00%) & 14 / 37 (37.84%) & 14 / 43 (32.56%) & 0 / 638 / 0 (0%/100%/0%) & -1082619.9 & -1082562.3 & 0.10 & 5762584 (9.23%) & 0.8 & 0.2 & 0.6 & NaN & NaN \\\\\n",
      "sweepmap-slow & 638 & 118 & 118 & 93 / 416 (22.36%) & 24 & 24 & 10 / 58 (17.24%) & 14 / 59 (23.73%) & 9 / 25 (36.00%) & 9 / 37 (24.32%) & 7 / 43 (16.28%) & 0 / 638 / 0 (0%/100%/0%) & -1045488.8 & -1045465.6 & 0.10 & 5981227 (9.58%) & 1.0 & 60.7 & 0.7 & NaN & NaN \\\\\n",
      "mapquik & 638 & 206 & 206 & 155 / 365 (42.47%) & 31 & 31 & 17 / 52 (32.69%) & 20 / 54 (37.04%) & 10 / 21 (47.62%) & 15 / 29 (51.72%) & 20 / 41 (48.78%) & 76 / 562 / 0 (12%/88%/0%) & -844564.3 & -844567.0 & 0.09 & 5210632 (8.34%) & 0.6 & -0.0 & 1.5 & NaN & NaN \\\\\n",
      "blend & 638 & 204 & 124 & 188 / 416 (45.19%) & 66 & 61 & 22 / 58 (37.93%) & 19 / 59 (32.20%) & 12 / 25 (48.00%) & 14 / 37 (37.84%) & 15 / 43 (34.88%) & 0 / 543 / 95 (0%/85%/15%) & -999652.6 & -1000080.2 & 0.12 & 5610945 (8.98%) & 1.1 & 3.9 & 0.2 & 80.000000 & 5.000000 \\\\\n",
      "minimap & 638 & 110 & 53 & 91 / 416 (21.88%) & 23 & 16 & 10 / 58 (17.24%) & 8 / 59 (13.56%) & 7 / 25 (28.00%) & 8 / 37 (21.62%) & 9 / 43 (20.93%) & 0 / 557 / 81 (0%/87%/13%) & -1044700.3 & -1044910.7 & 0.14 & 5763502 (9.23%) & 1.6 & 17.8 & 0.4 & 57.000000 & 7.000000 \\\\\n",
      "winnowmap & 638 & 89 & 52 & 83 / 416 (19.95%) & 41 & 25 & 9 / 58 (15.52%) & 10 / 59 (16.95%) & 9 / 25 (36.00%) & 9 / 37 (24.32%) & 10 / 43 (23.26%) & 0 / 572 / 66 (0%/90%/10%) & -1064044.2 & -1064158.5 & 0.12 & 5875957 (9.41%) & 2.7 & 689.2 & 0.5 & 37.000000 & 16.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(vcf_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
