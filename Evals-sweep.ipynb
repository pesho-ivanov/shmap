{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evals_header import *\n",
    "pd.set_option('display.max_rows', 200)\n",
    "T = 0.9\n",
    "\n",
    "def read_sweep(sweep_fn):\n",
    "    sweep_df = pd.read_csv(sweep_fn, sep='\\t', header=None)\n",
    "    sweep_df.columns = ['query_name', 'k', 'P_sz','p_sz', 'matches', 'ref_start', 'ref_end', 'minx', 'J', 'runtime']\n",
    "    sweep_df['J'] = sweep_df['J'].round(3)\n",
    "    sweep_df['alignment_bps'] = sweep_df['ref_end'] - sweep_df['ref_start']\n",
    "    return sweep_df\n",
    "\n",
    "def add_TP_column(tested_df, groundtruth_df, TP_column_name):\n",
    "    tested_df[TP_column_name] = tested_df.apply(lambda row: get_max_jaccard(row, groundtruth_df) >= T, axis=1)\n",
    "\n",
    "def get_sensitivity(tested_df, truth_df):\n",
    "    add_overlap_column(tested_df, truth_df, 'TP')\n",
    "    add_overlap_column(truth_df, tested_df, 'TP')\n",
    "\n",
    "    sensitivity = tested_df['TP'].sum() / tested_df.shape[0]  # TP / P\n",
    "    specificity = truth_df['TP'].sum() / truth_df.shape[0]  # 1 - FP / N \n",
    "\n",
    "    display(tested_df.head())\n",
    "    display(truth_df.head())\n",
    "\n",
    "    #correct = df[df['overlap'] > 0.1].shape[0]\n",
    "    #all = df.shape[0]\n",
    "    #accuracy = correct / all\n",
    "    #return correct, all, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_time_hist(df):\n",
    "#    plt.figure(figsize=(10, 6))\n",
    "#    #plt.hist(df[\"runtime\"], cumulative=True, bins=20, log=True)\n",
    "#    plt.hist(df[\"runtime\"], bins=20, cumulative=True, color='green', alpha=0.7, weights=df[\"runtime\"])\n",
    "#    plt.xlabel(\"Runtime\")\n",
    "#    plt.ylabel(\"Cumulative Runtime\")\n",
    "#    plt.title(\"Histogram of Runtime with Cumulative Runtime on Y-axis (Logarithmic X-axis)\")\n",
    "#    plt.xscale(\"log\")\n",
    "#    plt.show()\n",
    "\n",
    "def plot_time_hist(df):\n",
    "    df_sorted = df.sort_values(by='runtime')\n",
    "\n",
    "    # Calculate the cumulative sum\n",
    "    cumulative_sum = df_sorted['runtime'].cumsum()\n",
    "    display(cumulative_sum.head())\n",
    "    display(cumulative_sum.tail())\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    runtime_array = df_sorted['runtime'].to_numpy()\n",
    "    cumulative_sum_array = cumulative_sum.to_numpy()\n",
    "    #print('total time: ', cumulative_sum_array[-1])\n",
    "\n",
    "    # Create the line plot\n",
    "    #plt.plot(runtime_array, cumulative_sum_array)\n",
    "\n",
    "    # Add red dots for each data point\n",
    "    plt.scatter(runtime_array, cumulative_sum_array)\n",
    "\n",
    "    # Labeling the axes\n",
    "    plt.xlabel('Runtime (seconds)')\n",
    "    plt.ylabel('Cumulative Sum of Runtimes')\n",
    "    plt.title('Cumulative Sum of Runtimes')\n",
    "\n",
    "    # Adjusting the scale if necessary\n",
    "    plt.xscale('log')  # Use logarithmic scale if the range of runtimes is large\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input\n",
    "#reads_fn = 'simulations/reads/t2thumanChrY_sr0.0001090909090909091_dr0.0009818181818181818_i0.0009090909090909091_sd7361077429744071834_lmn100_lmx1000000_lavg9000_ls7000_dp10_rm20.fasta'\n",
    "reads_fn = 'newevals/reads-ChrY-positive.fa'\n",
    "#eskemap_fn = 'out/eske100.out'\n",
    "minimap_fn = 'out/minimap.out'\n",
    "#sweep_fn = 'sweep-pairs-noblacklist.out'\n",
    "#sweep_fn = 'out/sweep-b-a-fine.out'\n",
    "#sweep_fn = 'sweep-normalized-intervals.out'\n",
    "\n",
    "# Minimap\n",
    "minimap_df = pd.read_csv(minimap_fn, sep='\\t', header=None)\n",
    "minimap_df.columns = ['query_name', 'query_len', 'query_start', 'query_end', 'strand', 'ref_name', 'ref_len', 'ref_start', 'ref_end', 'match_bases', 'total_bases', 'map_quality', 'cigar']\n",
    "\n",
    "# Simulated reads\n",
    "simulated_df = parse_fasta_metadata(reads_fn)\n",
    "\n",
    "sweep_dfs = {}\n",
    "params_dfs = pd.DataFrame()\n",
    "# all files in which start with \"sweep_\"\n",
    "for sweep_fn in glob.glob('out/sweep*.out'):\n",
    "    print(sweep_fn)\n",
    "    sweep_dfs[sweep_fn] = read_sweep(sweep_fn)\n",
    "    sweep_dfs[sweep_fn] = pd.merge(simulated_df, sweep_dfs[sweep_fn], on='query_name', how='left')\n",
    "    add_overlap_column(sweep_dfs[sweep_fn], minimap_df, 'overlap')\n",
    "    correct, all, accuracy = get_accuracy(sweep_dfs[sweep_fn])\n",
    "    # sensitivity = get_sensitivity(sweep_dfs[sweep_fn], minimap_df)\n",
    "    # change the extension to '.params'\n",
    "    continue\n",
    "    params_fn = sweep_fn.replace('.out', '.params')\n",
    "    params_df = pd.read_csv(params_fn, sep='\\t')\n",
    "    params_df['correct'], params_df['all'],params_df['accuracy'] = correct, all, accuracy\n",
    "    #print('{} {:.2%} ({} / {})'.format(sweep_fn, accuracy, correct, all))\n",
    "    params_dfs = pd.concat([params_dfs, params_df], axis=0)\n",
    "# Sweep algo\n",
    "display(params_dfs)\n",
    "\n",
    "# Eskemap\n",
    "#eskemap_df = pd.read_csv(eskemap_fn, sep='\\t', header=None)\n",
    "#eskemap_df.columns = ['query_name', 'ref_start', 'ref_end', 'jaccard_scoreX1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "for fn, df in sweep_dfs.items():\n",
    "    # sort df decreasingly by 'runtime' column\n",
    "    df = df.sort_values(by='runtime', ascending=False)\n",
    "    display(df.head(10))\n",
    "    display(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop for each sweep df\n",
    "for fn, df in sweep_dfs.items():\n",
    "    print('  {:<25} unique reads={:<5} mean overlap={:.2%}'.format(fn, len(df['query_name'].unique()), df['overlap'].mean()))\n",
    "    print('  total runtime: ', df['runtime'].sum())\n",
    "    plot_time_hist(df)\n",
    "#print('  Sweep avg overlap: {:.8}'.format(sweep_df['overlap'].mean()))\n",
    "#sweep_df.to_csv('out/all.csv', sep='\\t', index=False)\n",
    "#plot_all_columns(sweep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'out/sweep-Y-x.out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_88301/2611102063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msweep_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msweep_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out/sweep-Y-x.out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msweep_misaligned_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msweep_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msweep_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overlap'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msweep_misaligned_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msweep_misaligned_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msweep_misaligned_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overlap'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# remove reads not aligned by minimap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msweep_misaligned_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_diff'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msweep_misaligned_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ref_start'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msweep_misaligned_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'from_ref_sim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'out/sweep-Y-x.out'"
     ]
    }
   ],
   "source": [
    "sweep_df = sweep_dfs['out/sweep-Y-x.out']\n",
    "sweep_misaligned_df = sweep_df[sweep_df['overlap'] < 0.1]\n",
    "sweep_misaligned_df = sweep_misaligned_df[sweep_misaligned_df['overlap'] >= 0]  # remove reads not aligned by minimap\n",
    "sweep_misaligned_df['start_diff'] = sweep_misaligned_df['ref_start'] - sweep_misaligned_df['from_ref_sim']\n",
    "\n",
    "display(sweep_misaligned_df[sweep_misaligned_df['start_diff'] > 0].head(10))\n",
    "\n",
    "print('Number of misaligned reads:', sweep_misaligned_df.shape[0])\n",
    "sweep_misaligned_df.to_csv('out/misalignments.csv', sep='\\t', index=False)\n",
    "#plot_all_columns(sweep_misaligned_df)\n",
    "display(sweep_misaligned_df.head(10))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
